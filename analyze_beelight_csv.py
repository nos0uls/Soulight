"""
analyze_encoding.py
-------------------
–ë–µ—Ä—ë—Ç –¥–≤–∞ –ª–æ–≥–∞ (—á—ë—Ä–Ω—ã–π —ç–∫—Ä–∞–Ω –∏ –±–µ–ª—ã–π —ç–∫—Ä–∞–Ω) –∏ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –±–∞–π—Ç—ã,
—á—Ç–æ–±—ã –ø–æ–Ω—è—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Ü–≤–µ—Ç–æ–≤.

–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:
1. –ó–∞–ø—É—Å—Ç–∏ Beelight –≤ —Ä–µ–∂–∏–º–µ Screen Mirroring
2. –°–¥–µ–ª–∞–π —ç–∫—Ä–∞–Ω –ü–û–õ–ù–û–°–¢–¨–Æ –ß–Å–†–ù–´–ú (PowerPoint/Paint —Å —á—ë—Ä–Ω—ã–º —Ñ–æ–Ω–æ–º)
3. –ó–∞–ø–∏—à–∏ –ª–æ–≥ 3-5 —Å–µ–∫—É–Ω–¥ ‚Üí —Å–æ—Ö—Ä–∞–Ω–∏ –∫–∞–∫ black.csv
4. –°–¥–µ–ª–∞–π —ç–∫—Ä–∞–Ω –ü–û–õ–ù–û–°–¢–¨–Æ –ë–ï–õ–´–ú
5. –ó–∞–ø–∏—à–∏ –ª–æ–≥ 3-5 —Å–µ–∫—É–Ω–¥ ‚Üí —Å–æ—Ö—Ä–∞–Ω–∏ –∫–∞–∫ white.csv
6. –ó–∞–ø—É—Å—Ç–∏: python analyze_encoding.py black.csv white.csv
"""

import sys, csv, re

CANDIDATE_ENCODINGS = ["utf-8-sig", "utf-16", "cp1251", "cp1252", "latin-1"]

def read_text(path):
    raw = open(path, "rb").read()
    for enc in CANDIDATE_ENCODINGS:
        try:
            return raw.decode(enc)
        except UnicodeDecodeError:
            pass
    return raw.decode("latin-1", errors="replace")

def sniff_delimiter(sample):
    try:
        return csv.Sniffer().sniff(sample, delimiters=";,").delimiter
    except:
        return ";"

def get_write_packets(path):
    text = read_text(path)
    delim = sniff_delimiter("\n".join(text.splitlines()[:50]))
    reader = csv.DictReader(text.splitlines(), delimiter=delim)
    fields = {n.strip(): n for n in (reader.fieldnames or [])}
    col_func = fields.get("Function")
    col_data = fields.get("Data")
    packets = []
    for row in reader:
        func = (row.get(col_func) or "").strip()
        if func != "IRP_MJ_WRITE":
            continue
        raw = (row.get(col_data) or "").strip()
        raw = re.sub(r"[^0-9a-fA-F ]", "", raw)
        raw = re.sub(r"\s+", " ", raw).strip().upper()
        if len(raw) > 10:
            packets.append(raw)
    return packets

def to_bytes(hex_str):
    return bytes.fromhex(hex_str.replace(" ", ""))

def get_long_packets(packets, min_len=100):
    """–¢–æ–ª—å–∫–æ –¥–ª–∏–Ω–Ω—ã–µ –ø–∞–∫–µ—Ç—ã (–¥–∞–Ω–Ω—ã–µ —Ü–≤–µ—Ç–æ–≤)"""
    result = []
    for p in packets:
        b = to_bytes(p)
        if len(b) >= min_len:
            result.append(b)
    return result

def analyze_two_logs(black_path, white_path):
    print(f"–ß–∏—Ç–∞—é {black_path}...")
    black_pkts = get_long_packets(get_write_packets(black_path))
    print(f"  –î–ª–∏–Ω–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤: {len(black_pkts)}")

    print(f"–ß–∏—Ç–∞—é {white_path}...")
    white_pkts = get_long_packets(get_write_packets(white_path))
    print(f"  –î–ª–∏–Ω–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤: {len(white_pkts)}")

    if not black_pkts or not white_pkts:
        print("–ù–µ—Ç –¥–ª–∏–Ω–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤!")
        return

    # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—ã–π —Å—Ç–∞–±–∏–ª—å–Ω—ã–π –ø–∞–∫–µ—Ç –∏–∑ –∫–∞–∂–¥–æ–≥–æ
    # (–±–µ—Ä—ë–º –∏–∑ —Å–µ—Ä–µ–¥–∏–Ω—ã, —á—Ç–æ–±—ã –Ω–µ –ø–æ–ø–∞—Å—Ç—å –Ω–∞ –ø–µ—Ä–µ—Ö–æ–¥–Ω—ã–π)
    b_pkt = black_pkts[len(black_pkts)//2]
    w_pkt = white_pkts[len(white_pkts)//2]

    min_len = min(len(b_pkt), len(w_pkt))
    print(f"\n–î–ª–∏–Ω–∞ —á—ë—Ä–Ω–æ–≥–æ –ø–∞–∫–µ—Ç–∞:  {len(b_pkt)} –±–∞–π—Ç")
    print(f"–î–ª–∏–Ω–∞ –±–µ–ª–æ–≥–æ –ø–∞–∫–µ—Ç–∞:   {len(w_pkt)} –±–∞–π—Ç")
    print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ {min_len} –±–∞–π—Ç\n")

    print("=== –ü–ï–†–í–´–ï 20 –ë–ê–ô–¢: –ß—ë—Ä–Ω—ã–π vs –ë–µ–ª—ã–π ===")
    print(f"{'–ü–æ–∑–∏—Ü–∏—è':>8}  {'–ß—ë—Ä–Ω—ã–π':>8}  {'–ë–µ–ª—ã–π':>8}  {'–†–∞–∑–Ω–∏—Ü–∞':>8}  {'XOR':>8}")
    for i in range(min(20, min_len)):
        bc = b_pkt[i]
        wc = w_pkt[i]
        diff = wc - bc
        xor  = bc ^ wc
        print(f"{i:>8}  {bc:>8}  {wc:>8}  {diff:>8}  {xor:>8X}")

    print("\n=== –ê–ù–ê–õ–ò–ó –ü–û–í–¢–û–†–Ø–Æ–©–ò–•–°–Ø –ü–ê–¢–¢–ï–†–ù–û–í –í –ß–Å–†–ù–û–ú –ü–ê–ö–ï–¢–ï ===")
    # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω (—à–∞–≥ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è)
    for step in [1, 2, 3, 4]:
        values = [b_pkt[i] for i in range(0, min(60, len(b_pkt)), step)]
        unique = set(values)
        print(f"  –®–∞–≥ {step}: {len(unique)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π -> {sorted(unique)[:10]}")

    print("\n=== –ì–ò–ü–û–¢–ï–ó–ê: XOR-–∫–ª—é—á ===")
    # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ XOR-—è—Ç—Å—è —Å –∫–ª—é—á–æ–º, —Ç–æ black XOR white = –∫–ª—é—á XOR (0,0,0) XOR –∫–ª—é—á XOR (255,255,255) = (255,255,255)
    # –¢.–µ. –≤—Å–µ –ø–æ–∑–∏—Ü–∏–∏ –¥–æ–ª–∂–Ω—ã –¥–∞–≤–∞—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π XOR
    xors = [b_pkt[i] ^ w_pkt[i] for i in range(min(60, min_len))]
    print(f"  XOR –ø–µ—Ä–≤—ã—Ö 60 –±–∞–π—Ç: {[hex(x) for x in xors[:20]]}")
    unique_xors = set(xors[:60])
    if len(unique_xors) == 1:
        print(f"  ‚úÖ XOR –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–π! –ö–ª—é—á = {hex(list(unique_xors)[0])}")
    elif len(unique_xors) <= 4:
        print(f"  üî∂ XOR –ø–æ—á—Ç–∏ –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–π: {unique_xors}")
    else:
        print(f"  ‚ùå XOR –Ω–µ–ø–æ—Å—Ç–æ—è–Ω–Ω—ã–π ({len(unique_xors)} —Ä–∞–∑–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π) ‚Äî –ø—Ä–æ—Å—Ç–æ–≥–æ XOR –Ω–µ—Ç")

    print("\n=== –°–´–†–´–ï –ë–ê–ô–¢–´ –ü–ï–†–í–´–• 5 –ü–ê–ö–ï–¢–û–í (–ß—ë—Ä–Ω—ã–π) ===")
    for i, pkt in enumerate(black_pkts[:5]):
        print(f"  –ü–∞–∫–µ—Ç {i}: {pkt[:30].hex(' ')}")

    print("\n=== –°–´–†–´–ï –ë–ê–ô–¢–´ –ü–ï–†–í–´–• 5 –ü–ê–ö–ï–¢–û–í (–ë–µ–ª—ã–π) ===")
    for i, pkt in enumerate(white_pkts[:5]):
        print(f"  –ü–∞–∫–µ—Ç {i}: {pkt[:30].hex(' ')}")

    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ —Ñ–∞–π–ª –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏
    with open("encoding_analysis.txt", "w", encoding="utf-8") as f:
        f.write(f"BLACK packet [{len(b_pkt)} bytes]:\n{b_pkt.hex(' ')}\n\n")
        f.write(f"WHITE packet [{len(w_pkt)} bytes]:\n{w_pkt.hex(' ')}\n\n")
        f.write("XOR positions 0-60:\n")
        f.write(" ".join(hex(x) for x in xors) + "\n")
    print("\n‚Üí –ü–æ–ª–Ω—ã–µ –ø–∞–∫–µ—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ encoding_analysis.txt")


def analyze_single(path):
    """–ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ñ–∞–π–ª ‚Äî –ø—Ä–æ—Å—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É"""
    print(f"–ß–∏—Ç–∞—é {path}...")
    all_pkts = get_write_packets(path)
    long_pkts = get_long_packets(all_pkts)
    short_pkts = [to_bytes(p) for p in all_pkts if len(to_bytes(p)) < 20]

    print(f"\n–ö–æ—Ä–æ—Ç–∫–∏–µ –ø–∞–∫–µ—Ç—ã (handshake):")
    for p in short_pkts[:15]:
        print(f"  {p.hex(' ')}")

    print(f"\n–î–ª–∏–Ω–Ω—ã–µ –ø–∞–∫–µ—Ç—ã - –ø–µ—Ä–≤—ã–µ 3:")
    for i, p in enumerate(long_pkts[:3]):
        print(f"  [{len(p)} bytes] {p[:40].hex(' ')}...")

    if long_pkts:
        with open("single_analysis.txt", "w", encoding="utf-8") as f:
            for i, p in enumerate(long_pkts[:10]):
                f.write(f"Packet {i} [{len(p)} bytes]:\n{p.hex(' ')}\n\n")
        print("\n‚Üí –ü–∞–∫–µ—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ single_analysis.txt")


if __name__ == "__main__":
    if len(sys.argv) == 3:
        analyze_two_logs(sys.argv[1], sys.argv[2])
    elif len(sys.argv) == 2:
        analyze_single(sys.argv[1])
    else:
        print("Usage:")
        print("  python analyze_encoding.py black.csv white.csv   # —Å—Ä–∞–≤–Ω–∏—Ç—å –¥–≤–∞ –ª–æ–≥–∞")
        print("  python analyze_encoding.py log.csv               # –∞–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ –ª–æ–≥–∞")